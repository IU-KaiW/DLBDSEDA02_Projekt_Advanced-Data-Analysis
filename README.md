# Aufgabe 1.1: NLP-Techniken anwenden, um eine Textsammlung zu analyieren
Ziel der Aufgabe ist es NLP-Techniken auf einen unstrukturierten, organisch entstandenen Datensatz mit schriftlichen Beschwerden anzuwenden und so die am hÃ¤ufigsten angesprochenen Themen aus den Texten zu extrahieren. Die hierdurch gewonnenen Informationen sollen im Anschluss fÃ¼r EntscheidungstrÃ¤ger (einer Ã¶rtlichen Stadtverwaltung) aufbereitet werden.<br>

Das zu erstellende schriftliche Konzept soll die Schritte der NLP-Datenverarbeitung mit Python darlegen. Dabei sollen kurz zwei Techniken zur Vektorisierung sowie zwei AnsÃ¤tze zur Extraktion von Themen aus dem Datensatz genannt und die zu verwendenten Python-Bibliotheken erwÃ¤hnt werden.

## Konzeption
Der Grafik kÃ¶nnen die geplanten Phasen des Projekts sowie die zugeordneten Prozesse entnommen werden. 

<img src="https://github.com/IU-KaiW/DLBDSEDA02_Projekt_Advanced-Data-Analysis/blob/main/docs/Visualisierung.jpg" width="1200">

      
### âšª Datenakquisition (engl. data acquisition)
> In der Phase der Datenaquisition werden DatensÃ¤tze fÃ¼r den Input der NLP-Pipeline gesucht, bewertet und ausgewÃ¤hlt. Hierzu wird ein trichterfÃ¶rmiger, vier stufiger Prozess Datensatzrecherche, â€“sammlung, â€“prÃ¼fung sowie â€“auswahl durchlaufen, an dessen Ende die Eingabe (engl. input) in die Pipeline steht.</br>
<ol>
    <details>
      <summary>âšª Datensatzrecherche (engl. dataset research)</b></summary>
      <i>Es wird eine Onlinerecherche auf verschiedenen Datenportalen (Kaggle, GitHub, GovData, MendeleyData, u.A.) durchgefÃ¼hrt und nach geeigneten deutschen und englischen DatensÃ¤tzen gesucht.</i></br>
    </details>
    <details>
      <summary>âšª Datensatzsammlung (engl. dataset collection)</summary>
      <i>Offensichtlich synthetisch erzeugte DatensÃ¤tze werden ignoriert. Datenquellen mit vermutetem organischen Ursprung werden im CSV-Datenformat heruntergeladen und lokal gespeichert.</i></br>
    </details>
    <details>
      <summary>âšª DatensatzprÃ¼fung (engl. dataset check)</summary>
      <i>Die gesammelten DatensÃ¤tze werden anhand eines KI-Text-Detectors auf synthetisch erzeugte Instanzen (engl. samples) geprÃ¼ft und mit Labels (REAL / FAKE / ERROR) getaggt. Dazu muss die Spaltenbeschriftung der textfÃ¼hrende Spalte in "text" umgenannt werden. </i><br>
    </details>
    <details>
      <summary>âšª Datensatzauswahl (engl. dataset selection)</summary>
      <i>Durch eine HÃ¤ufigkeitsauswertung der Label wird der Datensatz mit dem prozentual hÃ¶chsten Anteil an organischen (REAL-Label) Instanzen die die Formel:</i><br>
      <br>
      $$\%\text{ organisch} = \left(\frac{REAL}{REAL + FAKE + ERROR}\right) \cdot100$$
      <br>
      <br><i>ausgewertet. Die Wahrscheinlichkeit eines organischen Ursprungs erscheint hÃ¶her, je hÃ¶her der Prozentsatz organisch identifizierter Instanzen im VerhÃ¤ltnis zum Gesamtdatensatz ist. Kann ein Datensatz nicht in angemessener Zeit (30 min.) durch das Modell verarbeitet werden, wird die PrÃ¼fung abgebrochen und die Bewertung als n/a markiert. Der Datensatz flieÃŸt dann nicht in den Ergebnisvergleich ein.</i>
    </details>
</ol>
Der Datensatz mit der prozentualen hÃ¶chsten Bewertung wird als Korpus bzw. Pipeline Eingabe (engl. Pipeline-Input) fÃ¼r die nachfolgenden Schritte genutzt. Ãœbersteigt die Anzahl der Instanzen die Schwelle von 2000, wird der Datensatz fÃ¼r die folgenden Verarbeitungschritte die Anzahl begrenzt.<br><br>


| Nr.| Bezeichnung                        | Bewertung | GrÃ¶ÃŸe     |Quelle                     |
|----|------------------------------------|-----------|-----------|---------------------------|
| 01 | Consumer_Complaints.csv            | n/a       | 59,40  MB |[^01] &nbsp; Kaggle        |
| 02 | rows.csv                           | n/a       | 176    MB |[^02] &nbsp; Kaggle        |
| 03 | Consumer_Complaints.csv            | 13,5 %    | 107,0  MB |[^03] &nbsp; Kaggle/GovData|
| 04 | complaints_processed.csv           | 64,72 %   | 19,8   MB |[^04] &nbsp; Kaggle        |
| 05 | Comcast.csv                        | 82 %      | 60,0   kB |[^05] &nbsp; Kaggle        |
| 06 | user_complaints                    | 0,69 %    | 229,0  kB |[^06] &nbsp; GitHub        |
| 07 | consumer_complaints.csv            | n/a       | 175,39 MB |[^07] &nbsp; Kaggle        |
| 08 | Complaints_Reports_Data.sql        | n/a       | 3,28   MB |[^08] &nbsp; MendeleyData  |
| 09 | chatgpt_reviews.csv                | 35,03 %   | 119,9  MB |[^09] &nbsp; GitHub        |
| 10 | dataset-tickets-multi-lang3-4k.csv | n/a       | 6,87   MB |[^10] Kaggle               |
______________

###### Pipeline-Eingabe
Es wird Datensatz Nr. 5 "Comcast.csv"[^05]: mit der Bewertung von 82 % gewÃ¤hlt und als Input fÃ¼r die NLP-Pipeline genutzt.

### âš« Sprachverarbeitung (engl. NLP-Pipeline)
Merkmale (engl. features) eines Textes oder Dokuments sind Informationen wie LÃ¤nge (engl. length), Quelle (engl. source) und Datum der VerÃ¶ffentlichungsdatum (engl. date of publication)

Haupt Freatures / SekundÃ¤rfeatuers?

#### ğŸ”´ Datenvorverarbeiten (engl. data pre-processing)
> Durch die Datenvorverarbeiten erfolgt eine *Merkmalsvorbereitung (engl. feature preparation)* fÃ¼r nachfolgende Phasen in einem mehrstufigen Prozess, welcher sich grob die Prozesse Textbereinigung und Merkmalsextraktion einteilen lÃ¤sst.
<ol type="1">
  <details>
    <summary>ğŸ”´ Textbereinigung (engl. text cleaning)</summary>
    <p><i>Im Rahmen der Textbereinigung werden Texte zunÃ¤chst standardisiert und anschlieÃŸend von Rauschen befreit.</i></p>
    <ol type="1">
      <li>
        <ins>Standardisierung (engl. standardisation)</ins><br>
        <i>Im Rahmen der Textbereinigung werden Texte zunÃ¤chst standadisiert, um inhaltlich relevanten Tokens zu vereinheitlichen. Hierdurch wird vermieden, dass gleiche Inhalte nicht in mehreren, leicht unterschiedlichen Varianten auftreten. </i>
      <ol type="2">
            <li>**Normalisierung (engl. normalisation)**</li>
            Durch die Normalisierung wird Text .... Sie setzt sich zusammen aus: 
            <ul>
              <li>Kasusumwandlung (engl. case conversion)</li>
              In diesem Schritt erfolgt eine konsequente Kleinschreibung (engl. lowercasing) aller WÃ¶rter.
              <li>Grundformreduktion (engl. inflection reduction)</li>
              Durch diesen Schritt werden WÃ¶rter auf ihre Grundformen reduziert. Da Lemmatisierung (engl. lemmatization) genauer als Stammformreduktion (engl. stemming) ist, wird diese eingesetzt. (WordNet lemmatizer from NLTK)
              <li>Formatnormalisierungen (engl. format normalisations)</li>
            </ul>
            <li>Rechtschreibfehlerkorrektur (engl. spelling correction)</li>
            Durch Rechtschreibkorrekrur werden Tipp bzw. Schreibfehler korrigiert.
      </ol>
      </li>
      <li>
        Rauschentfernung (engl. noise reduction)<br>
        <i>Ziel der Rauschentfernung ist es, fÃ¼r die Verarbeitung irrelevante Tokens durch eine Zeichenentfernung zu lÃ¶schen.</i>
            <ol type="2">
            <li>Stoppworte (engl. stopwords)</li>
            <li>Satzzeichen (engl. punctuation marks)</li>
            <li>Leerzeichen (engl. white space)</li>
            <li>Nummern (engl. removing numbers)</li>
            <li>Sonderzeichen (engl. special character)</li>
      </ol>
    </ol>
  </details>

  <details>
    <summary>ğŸ”´ Merkmalsextraktion (engl. feature extraction)</summary>
    <p><i>Durch Merkmalsextraktion wird Text im Rahmen der Merkmalsvorbereitung zur weiteren Verarbeitung prÃ¤pariert.</i></p>
    <ol type="1">
      <li>
        Tokenisierung (engl. tokenization)<br>
        <i>Durch Tokenisierung wird der vorbereitet Text in Einzeltoken oder Phrasen (n-Gramme) zerlegt.</i>
        SpaCy
      </li>
      <li>
        Vokabularerstellung/Wortschatzaufbau (engl. Vocabulary Construction)<br>
        <i>Im Schritt des Wortschatzaufbaus (Vocabulary Construction) wird aus dem tokenisierten Textcorpus ein endliches Vokabular erstellt, das alle einzigartigen Tokens enthÃ¤lt und als Basis fÃ¼r nachfolgende Modelle dient.</i>
      </li>
    </ol>
  </details>
</ol>

#### ğŸŸ¤ Datenverarbeitung (engl. data processing)
> Datenverarbeitung erfolgt durch Merkmalsaufbereitung (engl. feature engineering) und Modellbildung (engl. modeling). Bei Merkmalsaufbereitung werden Rohdaten in Merkmale (engl. features) umgewandelt werden, welche ein Modell im Anschluss nutzen kann. Bei Modellbildung werden

Merkmalsaufbereitung kann in Merkmalsextraktion, Merkmalsumwandlung, Merkmalskonstruktion und Merkmalsauswahl unterteilt werden. Im Merkmalslernen erfolgt die Bildung von Modellen ohne Feature Engineering, basierend auf ...
<ol>
  <details>
    <summary>ğŸŸ¤ Vektorisierung (engl. vectorization)</summary>
    <p><i>Vektorisierungstechniken wandeln Text in Embeddings, nummerische ReprÃ¤sentationen um. Hierbei wird zwischen unsemantischen Embeddings (feature vektors) und semantischen Varianten (word vectors / sentence vectors) differenziert. Vektorisierungstechniken nutzen Merkmalsextraktion, um Text im Rahmen der Merkmalsaufbereitung fÃ¼r nachfolgende Schritte vorzubereiten.</i></p>
    <ol type="1">
       <li>unsemantische Embeddings</li>
       Hierunter werden 
          <ul>
            <li>Frequency Based Embedding</li>
           BoW, TF-IDF
          </ul>
       <li>semantische Embeddings</li>
          <ul>
            <li>Prediction Based Word Embedding</li>
            GloVE; Word2Vec, FastText
            <li>Contextualized Based Word Embedding</li>
            ELMO, BERT, GPT
          </ul>
  </details>
  <details>
    <summary>ğŸŸ¤ Text Analyse (engl. Text Analytics)</summary>
    <p><i>Beginn der Textanalyse (engl. Text Analytics), in welcher Merkmalsmodellierung (engl. feature modeling) und die Merkmalserkennung (engl. feature recognition) zu verorten sind.</i></p>
    <ol type="1">
       <li>ğŸŸ¤ Merkmalsmodellierung (engl. feature modeling)</li>
       Unter Merkmalsmodellierung versteht man die inhaltliche Strukturierung und Deutung des zuvor vektorisierten Texts. Sie legt fest, wie Merkmale thematisch oder semantisch fÃ¼r die Textanalyse genutzt werden kÃ¶nnen. Ãœber Themenmodellierung (engl. topic modeling) kÃ¶nnen Themen unÃ¼berwacht (engl. unsuperviced) mittels Merkmalsextraktion oder Merkmalsumwandlung identifiziert werden.<br>
            <ol type="2">
            <li>ğŸŸ¤ Merkmalsextraktion (engl. feature extraction)</li><br>
            <i>Latent Dirichlet Allocation (LDA)</i>
            Identifiziert latente Themen in einer Sammlung von Dokumenten und stellt Dokumente basierend auf ihren Verteilungen Ã¼ber diese Themen dar.<br>
           <br><li>ğŸŸ¤ Merkmalsumwandlung (engl. feature transformation)<br></i></li>
            <i>Latent Semantic Analysis (LSA)</i><br>
            <li>ğŸŸ¤ Merkmalsauswahl (engl. feature selection)<br>
            <i>Zum Ende werden die besten Merkmale ausgewÃ¤hlt.</i>
          </ol>
       <li>ğŸŸ¤ Merkmalserkennung (engl. feature recognition)</li>
          <ol>
            <li>1</li>
            xxx
            <li>2</li>
            xxx
          </ol>
  </details>
  <details>
    <summary>ğŸŸ¤  Merkmalslernen (engl. feature learning / representation learning)</summary></br>
    In der Datenverarbeitung beginnt die Merkmalsaufbereitung (engl. feature engineering) und das Merkmalslernen (engl. feature learning / representation learning).
    <i>Beginn der Modellbildung fÃ¼r Aufgabe<i>
  </details>
</ol>

###### Pipeline Ausgabe (engl. Pipeline Output)
______________

### ğŸ”µ Datenkonsolidierung (engl. data consolidation)
> Im Rahmen der Datenkonsolidierung erfolgt die Datennachverarbeitung (engl. data post-processing) in der die Merkmalsanalysen (engl. feature analysis) sowie die Modellevaluationen (engl. model evaluations) durchgefÃ¼hrt und letztlich als DatenprÃ¤sentation (engl. data presentation) aufbereitet werden.


Datenauswertung (engl. data analysis)
____
<ol>
    <details>
      <summary>âšª Merkmalsauswertungen (engl. feature Inspections)</summary>
      <p><i>Themenverteilungen; Top-WÃ¶rter pro Thema; ğ›¼ (Alpha) â€“ Themenmischung pro Dokument; Î² (Beta) â€“ Wortverteilung in Themen; K<sup>T</sup> (n Ã— k)</i></p>
          <details>
            <summary><ins>â†³ Aggregation (engl.)</ins></summary>
            <p><i>alphanumerische Darstellungen - Aggregation reduziert die Datenmenge durch mathematische Operationen wie Summe, Mittelwert, ZÃ¤hlung oder Maximum Ã¼ber Gruppierungen (z. B. nach Token-Typ, Dokument oder Zeitraum). In NLP kÃ¶nnte dies die HÃ¤ufigkeitsverteilung von n-Grammen pro DomÃ¤ne oder die durchschnittliche Embedding-Distanz pro Klasse bedeuten. Sie erfolgt vor der Visualisierung, um Ãœberladung zu vermeiden, und ist rein datenverarbeitend ohne grafische Elemente. Aggregation fasst Rohdaten zu kompakteren Zusammenfassungen zusammen.</i></p>
          </details>
          <details>
            <summary><ins>â†³ Visualisierung (engl.)</ins></summary>
            <p><i>grafische Darstellung - Visualisierung stellt die aggregierten Daten grafisch dar, um Muster erkennbar zu machen.<</i></p>
        <ul>
          <li>PyLDAvis</li>
        </ul>
          </details>
    </details>
  </li>
      <details>
      <summary>âšª Modellauswertung (engl. model evaluation)</summary>
      <p><i>Modellvergleich / Modellperformance; Evaluation (engl. model evaluation)</p>
          <details>
            <summary><ins>â†³ KohÃ¤renz</ins></summary>
            <p><i>Coherence</i></p>
          </details>
          <details>
            <summary><ins>â†³ Perplexity</ins></summary>
            <p><i>Perplexity</i></p>
          </details>
    </details>
  </li>
</ol>
______________


<ol>
  <li>
    <details>
      <summary>âšª Merkmalsauswertungen (engl. feature Inspections)</summary>
      <p><i>Themenverteilungen; Top-WÃ¶rter pro Thema; ğ›¼ (Alpha) â€“ Themenmischung pro Dokument; Î² (Beta) â€“ Wortverteilung in Themen; K<sup>T</sup> (n Ã— k)</i></p>
      
      <details>
        <summary><ins>â†³ Aggregation (engl.)</ins></summary>
        <p><i>alphanumerische Darstellungen - Aggregation reduziert die Datenmengeâ€¦</i></p>
      </details>
      
      <details>
        <summary><ins>â†³ Visualisierung (engl.)</ins></summary>
        <p><i>grafische Darstellung - Visualisierung stellt die aggregierten Daten grafisch darâ€¦</i></p>
        <ul>
          <li>PyLDAvis</li>
        </ul>
      </details>
    </details>
  </li>
  
  <li>  <!-- â† HIER fehlte das <li> fÃ¼r EinrÃ¼ckung! -->
    <details>
      <summary>âšª Modellauswertung (engl. model evaluation)</summary>
      <p><i>Modellvergleich / Modellperformance; Evaluation</i></p>
      
      <details>
        <summary><ins>â†³ KohÃ¤renz</ins></summary>
        <p><i>Coherence</i></p>
      </details>
      
      <details>
        <summary><ins>â†³ Perplexity</ins></summary>
        <p><i>Perplexity</i></p>
      </details>
    </details>
  </li>
</ol>


## Projektstruktur
### Ordnerstruktur
```markdown
â”œâ”€â”€ datasets/  # Roh- und vorverarbeitete Texte
â”œâ”€â”€ src/       # Python-Module
â”œâ”€â”€ docs/      # Abbildungen, PDFs
â””â”€â”€ README.md
```

## Installation (engl. setup)
### Vorbereitende Installation (engl. preparatory setup)
#### Datenvalidierung (engl. data validation)
KI Detektor

#### Laufzeitumgebung (engl. runtime environment)
Als virtuelle Umgebungen stehen in Python "conda" und "venv" zur VerfÃ¼gung. Aufgrund der Bibiliothek SpaCy wurde sich fÃ¼r conda entschieden.
```console
`pip install conda`
```
### Erstinstallation (engl. initial setup)

#### Voraussetzungen (engl. prerequisite setup)
##### AbhÃ¤ngigkeiten (engl. dependencies)

#### Bibliotheken (engl. librarys)
##### Sprachverarbeitung (engl. NLP-Pipeline)
##### Datenkonsolidierung (engl. data consolidation)
###### Visualisierung
###### Aggregation



```python
import pandas as pd
import numpy as np
import matplotlib as mpl
import seaborn as sns
```

`Cartopy`      https://cartopy.readthedocs.io/stable/getting_started/index.html<br>
`re`   
`csv`   
`matplotlib`   https://matplotlib.org<br>
`seaborn`      https://seaborn.pydata.org<br>
`spacy`        https://spacy.io<br>
`nltk`         https://www.nltk.org<br>
`pandas`
`Gensim`
`transformers`
`torch`        

### Referenzen
<ul>
<li>Externe Software</li>

###### Detektor
Kishan Jai Soorya N. AI-Text-Detector-Python. (https://github.com/Kishanjaisoorya/AI-Text-Detector-python)

<li>Bibliotheken (engl. librarys)</li>


###### Einrichtung (engl. initial setup)
`pandas` https://pandas.pydata.org<br>

###### VorprÃ¼fung
`transformers`https://pypi.org/project/transformers/<br>


###### NLP-Pipeline
`Gensim` https://pypi.org/project/gensim/<br>
Dokumentation: 

`SpaCy` https://spacy.io<br>
Dokumentation: 

`NLTK`https://www.nltk.org<br>
Dokumentation: 


###### Nachverarbeitung
Visualisierung
`matplotlib` https://matplotlib.org<br>
Dokumentation: 

`seaborn` https://seaborn.pydata.org<br>
Dokumentation: 

`PyLDAvis`     https://pypi.org/project/pyLDAvis/
Dokumentation: 

Evaluation


<li>Literatur</li>

###### Skripte
IU Internationale Hochschule. (2024). Advanced Data Analysis (DLBDSEDA01_D) [Lernskript]. 001-2024-1210.<br>

###### Wissenschaftliche Artikel
Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.: Latent dirichlet allocation. In: The Journal of Machine Learning Research. Nr. 3, 3. Januar 2003, S. 993â€“1022<br>
Blum et al., 2020 ?

Abbott, D., Kommer, I., & Kommer, C. (2025). Datenvisualisierung im praktischen Einsatz: Ansprechende Diagramme und Dashboards gestalte (1. Auflage). dpunkt.verlag.


<li>Websites</li>

###### GeekforGeek.org
Sanchhaya Education Private Ltd., 2025 (https://www.geeksforgeeks.org/nlp/nlp-gensim-tutorial-complete-guide-for-beginners/)
StudySmarter GmbH, 2025 (https://www.studysmarter.de/schule/informatik/computerlinguistik-theorie/feature-selection/)
Radim Å˜ehÅ¯Å™ek, 10.08.2024 - (https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#sphx-glr-auto-examples-tutorials-run-lda-py)
Christopher Helm, 08.05.2025 - (https://konfuzio.com/de/spacy-vs-nltk/)



https://www.kaggle.com<br>
https://www.github.com<br>
https://data.mendeley.com<br>

###### Dokumentationen
SpaCy -  https://spacy.io/usage/spacy-101<br>
GitHub - https://docs.github.com/de/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax<br>

</ul>

ğŸŸ£ ğŸŸ¢ğŸŸ ğŸ”´
ğŸ”µ ğŸŸ¡ğŸŸ¤âš«
https://emojiterra.com/de/gelber-kreis/




<ol>
  <details>
    <summary>ğŸŸ¤ Merkmalsextraktion (engl. feature extraction)</summary>
    <p><i>Durch Merkmalsextraktion wird Text im Rahmen der Merkmalsaufbereitung zur weiteren Verarbeitung vorbereitet.</i></p>
    <ol type="1">
      <li>
        Vektorisierung (engl. vectorization)<br>
        <i>Vektorisierungstechniken wandeln Text in nummerische ReprÃ¤sentationen Embeddings um. Hierbei wird zwischen unsemantischen Embeddings, die Feature Vektoren erzeugen und semantischen Varianten welche Word Embeddings erzeugen differenziert.</i>
      <ol type="2">
       <li>unsemantische Embeddings</li>
       Hierunter werden 
          <ul>
            <li>Frequency Based Embedding</li>
           BoW, TF-IDF
          </ul>
       <li>semantische Embeddings</li>
          <ul>
            <li>Prediction Based Word Embedding</li>
            GloVE; Word2Vec, FastText
            <li>Contextualized Based Word Embedding</li>
            ELMO, BERT, GPT
          </ul>
    </ol>
  </details>
</ol>

[^01]: [Datensatz01] (https://www.kaggle.com/datasets/ashwinik/consumer-complaints-financial-products)
[^02]: [Datensatz02] (https://www.kaggle.com/datasets/selener/consumer-complaint-database)
[^03]: [Datensatz03] (https://www.kaggle.com/code/saurabhsawhney/nlp-complaints-classification)
[^04]: [Datensatz04] (https://www.kaggle.com/datasets/shashwatwork/consume-complaints-dataset-fo-nlp)
[^05]: [Datensatz05] (https://www.kaggle.com/datasets/yasserh/comcast-telecom-complaints)
[^06]: [Datensatz07] (https://github.com/gurneetjuneja/NLP-Problem-Solving/blob/main/user_complaints.csv)
[^07]: [Datensatz08] (https://www.kaggle.com/code/mchirico/analyzing-text-in-consumer-complaints)
[^08]: [Datensatz09] (https://data.mendeley.com/datasets/w2cp7h53s5/1)
[^09]: [Datensatz10] (https://github.com/Schossi2908/DLBDSEDA02_D)
[^10]: [Datensatz11] (https://www.kaggle.com/datasets/tobiasbueck/multilingual-customer-support-tickets)

<ol> 
  <details>
    <summary>âšª Datenauswertung (engl. data analysis)</summary>
    <p><i>Merkmalsauswertungen (engl. feature Inspections)</i></p>
    <ol type="1">
      <p><i>Themenverteilungen; Top-WÃ¶rter pro Thema</i></p>
        ğ›¼ (Alpha) - Themenmischung pro Dokument<br>
        Î² (Beta) - Wortverteilung in Themen<br>
        K<sup>T</sup> (n Ã— k)
    <summary> Evaluation (engl. model evaluation)</summary>
    <i>Modellvergleich</i><br>
  </details>
<ol>
  <details>
    <summary>âšª DatenprÃ¤sentation (engl. data presentation)<br></summary>
    <summary>âšª Visualisierung</summary>
    <i>grafische Darstellung</i><br>
    <li>PyLDAvis</li>
  </details>
  <details>
    <summary>âšª DatenprÃ¤sentation (engl. data presentation)<br></summary>
    <summary>âšª Visualisierung</summary>
    <i>grafische Darstellung</i><br>
    <li>PyLDAvis</li>
    <summary>âšª Aggregation</summary>
    <i>numerische Darstellung</i>
    Modellperformance
  </details>
</ol>

<ol>
  <li>
    <details>
      <summary>âšª Datenauswertung (engl. data analysis)</summary>
      <p><i>xxxxxxx</i></p>
      <ol type="1">
        <li>
          <ins>Merkmalsauswertungen (engl. feature inspections)</ins>
          <p><i>Themenverteilungen; Top-WÃ¶rter pro Thema</i></p>
          ğ›¼ (Alpha) â€“ Themenmischung pro Dokument<br>
          Î² (Beta) â€“ Wortverteilung in Themen<br>
          K<sup>T</sup> (n Ã— k)
        </li>
        <li>
          <details>
            <summary>â†³ Evaluation (engl. model evaluation)</summary>
            <p><i>Modellvergleich</i></p>
          </details>
        </li>
      </ol>
    </details>
  </li>
  <li>
    <details>
      <summary>âšª DatenprÃ¤sentation (engl. data presentation)</summary>
      <details>
        <summary>â†³ Visualisierung</summary>
        <p><i>grafische Darstellung</i></p>
        <ul>
          <li>PyLDAvis</li>
        </ul>
      </details>
      <details>
        <summary>â†³ Aggregation</summary>
        <p><i>numerische Darstellung</i></p>
        Modellperformance
      </details>
    </details>
  </li>
</ol>