# Projekt: Advanced Data Analysis (DLBDSEDA02_D)

## Aufgabe 1.1: NLP-Techniken anwenden, um eine Textsammlung zu analyieren
Ziel der Aufgabe ist es NLP-Techniken auf einen unstrukturierten, organisch entstandenen Datensatz mit schriftlihen Beschwerden anzuwenden und so die am hÃ¤ufigsten angesprochenen Themen aus den Texten zu extrahieren. Die hierdurch gewonnenen Informationen sollen im Anschluss fÃ¼r EntscheidungstrÃ¤ger (einer Ã¶rtlichen Stadtverwaltung) aufbereitet werden. 

1. Schriftliches Konzept<br>
2. Datenverarbeitung<br>
2.1. Vektorisierung 2 Techniken<br>
2.2. Extraktion von Themen 2 AnsÃ¤tze.<br>

### Projektstruktur
#### Ordnerstruktur
```markdown
â”œâ”€â”€ datasets/  # Roh- und vorverarbeitete Texte
â”œâ”€â”€ src/       # Python-Module
â”œâ”€â”€ docs/      # Abbildungen, PDFs
â””â”€â”€ README.md
```
#### Installation
##### Golbal
###### Dependencies
##### Pipeline Eingabe
##### Pipeline Verarbeitung
##### Pipeline Ausgabe

<img src="https://github.com/IU-KaiW/DLBDSEDA02_Projekt_Advanced-Data-Analysis/blob/main/Projekt%20ADA%20v.3-Pipeline.jpg" width="500">

## Pipeline Eingabe (engl. Pipeline-Input)
<b>âšª Datenaquisition (engl. dataset acquisition)</b></br>
In der Phase der Datenaquisition werden DatensÃ¤tze fÃ¼r den Input der NLP-Pipeline gesucht, bewertet und ausgewÃ¤hlt. Hierzu wird ein trichterfÃ¶rmiger, vier stufiger Prozess Datensatzrecherche, â€“sammlung, â€“prÃ¼fung sowie â€“auswahl durchlaufen, an dessen Ende die Eingabe (engl. input) in die Pipeline steht.</br>
<ol>
    <details>
      <summary>âšª <u> Datensatzrecherche (engl. dataset research) <u></b></summary>
      <i>Es wird eine Onlinerecherche auf verschiedenen Datenportalen (Kaggle, GitHub, GovData, ect.) durchgefÃ¼hrt und nach geeigneten deutschen und englischen DatensÃ¤tzen gesucht.</i></br>
    </details>
    <details>
      <summary>âšª Datensatzsammlung (engl. dataset collection)</summary>
      <i>Offensichtlich synthetisch erzeugte DatensÃ¤tze werden ignoriert. Datenquellen mit vermutetem organischen Ursprung werden im CSV-Datenformat heruntergeladen und lokal gespeichert.</i></br>
    </details>
    <details>
      <summary>âšª DatensatzprÃ¼fung (engl. dataset check)</summary>
      <i>Die gesammelten DatensÃ¤tze werden anhand eines vorhandenen KI-Detectors auf synthetisch erzeugte Instanzen (engl. samples) geprÃ¼ft und mit Labels (Real / Fake / Error) getaggt.</i><br>
    </details>
    <details>
      <summary>âšª Datensatzauswahl (engl. dataset selection)</summary>
      <i>Durch eine HÃ¤ufigkeitsauswertung der Label wird der Datensatz mit dem prozentual hÃ¶chsten Anteil an organischen (REAL-Label) Instanzen die die Formel:</i><br>
      <br>
      $$\%\text{ organisch} = \left(\frac{REAL}{REAL + FAKE + ERROR}\right) \cdot100$$
      <br>
      <br><i>ausgewertet. Die Wahrscheinlichkeit eines organischen Ursprungs erscheint hÃ¶her, je hÃ¶her der Prozentsatz organisch identifizierter Instanzen im VerhÃ¤ltnis zum Gesamtdatensatz ist. Kann ein Datensatz nicht in angemessener Zeit (30 min.) durch das Modell verarbeitet werden, wird die PrÃ¼fung abgebrochen und der Datensatz flieÃŸt nicht in den Ergebnisvergleich ein.</i>
    </details>
</ol>

```markdown
| Nr. | Datensatz                          | Bewertung | GrÃ¶ÃŸe     | Quelle         | Link                                                                                 |
|-----|------------------------------------|-----------|-----------|----------------|--------------------------------------------------------------------------------------|
| 1   | Consumer_Complaints.csv            | n/a       | 59,40  MB | Kaggle         | https://www.kaggle.com/datasets/ashwinik/consumer-complaints-financial-products      |
| 2   | rows.csv                           | n/a       | 176    MB | Kaggle         | https://www.kaggle.com/datasets/selener/consumer-complaint-database                  |
| 3   | Consumer_Complaints.csv            | 13,5 %    | 107,0  MB | Kaggle/GovData | https://www.kaggle.com/code/saurabhsawhney/nlp-complaints-classification             |
| 4   | complaints_processed.csv           | 64,72 %   | 19,8   MB | Kaggle         | https://www.kaggle.com/datasets/shashwatwork/consume-complaints-dataset-fo-nlp       |
| 5   | Comcast.csv                        | 82 %      | 60,0   kB | Kaggle         | https://www.kaggle.com/datasets/yasserh/comcast-telecom-complaints                   |
| 7   | user_complaints                    | 0,69 %    | 229,0  kB | GitHub         | https://github.com/gurneetjuneja/NLP-Problem-Solving/blob/main/user_complaints.csv   |
| 8   | consumer_complaints.csv            | n/a       | 175,39 MB | Kaggle         | https://www.kaggle.com/code/mchirico/analyzing-text-in-consumer-complaints           |
| 9   | Complaints_Reports_Data.sql        | n/a       | 3,28   MB | MendeleyData   | https://data.mendeley.com/datasets/w2cp7h53s5/1                                      |
| 10  | chatgpt_reviews.csv                | 35,03 %   | 119,9  MB | GitHub         | https://github.com/Schossi2908/DLBDSEDA02_D                                          |
| 11  | dataset-tickets-multi-lang3-4k.csv | n/a       | 6,87   MB | Kaggle         | https://www.kaggle.com/datasets/tobiasbueck/multilingual-customer-support-tickets    |
```
Der Datensatz mit der prozentualen hÃ¶chsten Bewertung wird als Textkorpus fÃ¼r die nachfolgenden Aufgabe verwendet.

## NLP-Verarbeitungsschritte (engl. NLP-Pipeline)
Ãœbersteigt die Anzahl der Instanzen die Schwelle von 2000, wird der Datensatz fÃ¼r die folgenden Verarbeitungschritte auf diese Anzahl begrenzt.
Merkmale (engl. features) eines Textes oder Dokuments sind Informationen wie LÃ¤nge (engl. length), Quelle (engl. source) und Datum der VerÃ¶ffentlichungsdatum (engl. date of publication). 

### Vorverarbeitung (engl. pre-processing)
Das pre-processing

<b>ðŸ”´ Merkmalsvorbereitung (engl. feature preparation)</b></br>
*Beginn der der Merkmalsvorbereitung (engl. feature preparation).*
<ol>
    <details>
      <summary>ðŸ”´ Textbereinigung (engl. text cleaning)</b></summary>
      <i>xxxxx</i>
        <ol>
        <li> Standardisierung (engl. standardisation)<br></li>
        <i>xxxxx</i>
        <li> Rauschentfernung (engl. noise reduction)<br></li>
        <i>xxxxx</i>
        </ol>
    </details>
    <details>
      <summary>ðŸ”´ Merkmalsextraktion (engl. feature extraction)</summary>
      <i>xxxxx</i>
        <ol>
        <li>Tokenisierung (engl. tokenization)</li>
        <i>In diesem Schritt</i>
        <li>Vokabularerstellung/Wortschatzaufbau (engl. Vocabulary Construction)</li>
        <i>In diesem Schritt</i>
        </ol>
    </details>
</ol>


### Verarbeitung (engl. processing)

<b>ðŸŸ  Merkmalsaufbereitung (engl. feature engineering)</b></br>
*Beginn der Merkmalsaufbereitung (engl. feature engineering)*
<ol>
    <details>
      <summary>ðŸŸ  Merkmalsextraktion (engl. feature extraction)</summary>
      <i>xxxxx</i>
        <ol>
        <li>Vektorisierung</li>
        <i>In diesem Schritt</i>
       <ul>
          <li><a prerequisites>Frequency Based Embedding</a></li>
           TF-IDF
          <li><a installation>Prediction Based Word Embedding</a></li>
           GloVE; Word2Vec
          <li><a installation>Contextualized Based Word Embedding</a></li>
    </details>
</ol>

<b>ðŸŸ¡ Text Analyse (engl. Text Analytics)</b></br>
*Beginn der Textanalyse (engl. Text Analytics), bei der die Themenmodellierung beginnt, durch welche Themen aus dem Text extrahiert werden.*
<ol>
    <details>
      <summary><b>ðŸŸ¡ Merkmalsextraktion (engl. feature extraction)</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Beginn der Merkmalsextraktion zum Zweck der Themenmodellierung</i>
      <summary>Themenmodellierung (engl. topic modeling)</summary>
      <i>Beginn der Themenmodellierung</i>
           NMF, LDA
    </details>
    <details>
      <summary><b>ðŸŸ¡ Merkmalsumwandlung (engl. feature transformation)</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Beginn der Merkmalsumwandlung in der Merkmale in eine geeignete Form gebracht werden.</i>
          .<br>
      <summary>Themenmodellierung (engl. topic modeling)</summary>
      <i>Beginn der Themenmodellierung</i>
           LSA
    </details>
    <details>
      <summary><b>ðŸŸ¡ Merkmalsauswahl (engl. feature selection)</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zum Ende werden die besten Merkmale ausgewÃ¤hlt.</i>
    </details>
</ol>    
<b>ðŸ”µ Merkmalslernen (engl. feature learning / representation learning)</b></br>
<i>Beginn der Modellbildung fÃ¼r Aufgabe<i>

## Pipeline Ausgabe (engl. Pipeline Output)
<b>ðŸŸ¢ Merkmalsanalyse (engl. feature-analysis)</b></br>
      <i>xxxxxxxxxxxx</i>
<ol>
    <details>
      <summary><b>ðŸŸ¢ Visualisierung</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grafische Darstellung</i>
    </details>
    <details>
      <summary><b>ðŸŸ¢ Aggregation</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numerische Darstellun</i>
    </details>
</ol>

### Nachverarbeitung (engl. post-processing)
*Beginn der Evaluation*
<ol>
  <details>
      <summary>ðŸŸ£ Evaluation</summary>
      <ol>
        <li> Aggregation</li>
        <i>blub blub, blub</i>
        <li> Visualisierung</li>
        <i>blub blub, blub</i>
      </ol>
  </details>
</ol>

### Codeblocks
````python
33333
````

Installation


### 
ðŸ“Š Ergebnisse
Themenverteilungen
Top-WÃ¶rter pro Thema
Modellvergleich


### Referenzen
Detector
`KI-Detektor`

Bibliotheken
`Gensim`

<li>1</li>
````python
12535
````
Literatur
`Gensim`

<li>2</li>