# Projekt: Advanced Data Analysis (DLBDSEDA02_D)

## Aufgabe 1.1: NLP-Techniken anwenden, um eine Textsammlung zu analyieren
Ziel der Aufgabe ist es NLP-Techniken auf einen unstrukturierten, organisch entstandenen Datensatz mit schriftlihen Beschwerden anzuwenden und so die am hÃ¤ufigsten angesprochenen Themen aus den Texten zu extrahieren. Die hierdurch gewonnenen Informationen sollen im Anschluss fÃ¼r EntscheidungstrÃ¤ger (einer Ã¶rtlichen Stadtverwaltung) aufbereitet werden. 

1. Schriftliches Konzept<br>
2. Datenverarbeitung<br>
2.1. Vektorisierung 2 Techniken<br>
2.2. Extraktion von Themen 2 AnsÃ¤tze.<br>

### Projektstruktur
```markdown
â”œâ”€â”€ datasets/  # Roh- und vorverarbeitete Texte
â”œâ”€â”€ src/       # Python-Module
â”œâ”€â”€ docs/      # Abbildungen, PDFs
â””â”€â”€ README.md
```

<img src="https://github.com/IU-KaiW/DLBDSEDA02_Projekt_Advanced-Data-Analysis/blob/main/Projekt%20ADA%20v.3-Pipeline.jpg" width="500">

## Pipeline-Input
<b>âšª Datenaquisition (engl. dataset acquisition)</b></br>
In der Phase der Datenaquisition werden DatensÃ¤tze fÃ¼r den Input der NLP-Pipeline gesucht, bewertet und ausgewÃ¤hlt. Hierzu wird ein trichterfÃ¶rmiger, vier stufiger Prozess Datensatzrecherche, â€“sammlung, â€“prÃ¼fung sowie â€“auswahl durchlaufen, an dessen Ende die Eingabe (engl. input) in die Pipeline steht.</br>
<ol>
    <details>
      <summary>âšª Datensatzrecherche (engl. dataset research)</b></summary>
      <i>Es wird eine Onlinerecherche auf verschiedenen Datenportalen (Kaggle, GitHub, GovData, ect.) durchgefÃ¼hrt und nach geeigneten deutschen und englischen DatensÃ¤tzen gesucht.</i></br>
    </details>
    <details>
      <summary>âšª Datensatzsammlung (engl. dataset collection)</summary>
      <i>Offensichtlich synthetisch erzeugte DatensÃ¤tze werden ignoriert. Datenquellen mit vermutetem organischen Ursprung werden im CSV-Datenformat heruntergeladen und lokal gespeichert.</i></br>
    </details>
    <details>
      <summary>âšª DatensatzprÃ¼fung (engl. dataset check)</summary>
      <i>Die gesammelten DatensÃ¤tze werden anhand eines vorhandenen KI-Detectors auf synthetisch erzeugte Instanzen (engl. samples) geprÃ¼ft und mit Labels (Real / Fake / Error) getaggt.</i></br>
    </details>
    <details>
      <summary>âšª Datensatzauswahl (engl. dataset selection)</summary>
      <i>Anhand der Label wird der Datensatz mit dem hÃ¶chsten Score an organisch identifizierten Instanzen gewÃ¤hlt, da hier die Wahrscheinlichkeit eines organischen Ursprungs am hÃ¶chsten scheint.</i></br>
      <br>$$\% \text{organisch} = \frac{REAL}{REAL + FAKE + ERROR} \cdot 100$$</br>
      <br><i>Der so identifizierte Datensatz wird fÃ¼r weitere Verarbeitungsschritte genutzt. Ãœbersteigt die Anzahl der Samples eine Schwelle von 2000 wird der Datensatz zunÃ¤chst aus PerformancegrÃ¼nden gesplittet.</i></br>
</ol>
    </details>
    
$$
(dataset_{organisch})=\left(\frac{REAL}{REAL + FAKE + ERROR}\right)\cdot100
$$
## NLP-Verarbeitungsschritte (engl. NLP-Pipeline)
anhand von Kriterien wie

Features of Texts are: 

### Pre-Processing
*Das pre-processing

<b>ðŸ”´ Merkmalsvorbereitung (engl. feature preparation)</b></br>
*Beginn der der Merkmalsvorbereitung (engl. feature preparation).*
<ol>
    <details>
      <summary>ðŸ”´ Textbereinigung (engl. text cleaning)</b></summary>
      <i>xxxxx</i>
        <ol>
        <li> Standardisierung (engl. standardisation)<br></li>
        <i>xxxxx</i>
        <li> Rauschentfernung (engl. noise reduction)<br></li>
        <i>xxxxx</i>
        </ol>
    </details>
    <details>
      <summary>ðŸ”´ Merkmalsextraktion (engl. feature extraction)</summary>
      <i>xxxxx</i>
        <ol>
        <li>Tokenisierung (engl. tokenization)</li>
        <i>In diesem Schritt</i>
        <li>Vokabularerstellung/Wortschatzaufbau (engl. Vocabulary Construction)</li>
        <i>In diesem Schritt</i>
        </ol>
    </details>
</ol>


### Processing

<b>ðŸŸ  Merkmalsaufbereitung (engl. feature engineering)</b></br>
*Beginn der Merkmalsaufbereitung (engl. feature engineering)*
<ol>
    <details>
      <summary>ðŸŸ  Merkmalsextraktion (engl. feature extraction)</summary>
      <i>xxxxx</i>
        <ol>
        <li>Vektorisierung</li>
        <i>In diesem Schritt</i>
       <ul>
          <li><a prerequisites>Frequency Based Embedding</a></li>
           TF-IDF
          <li><a installation>Prediction Based Word Embedding</a></li>
           GloVE; Word2Vec
          <li><a installation>Contextualized Based Word Embedding</a></li>
    </details>
</ol>

<b>ðŸŸ¡ Text Analyse (engl. Text Analytics)</b></br>
*Beginn der Textanalyse (engl. Text Analytics), bei der die Themenmodellierung beginnt, durch welche Themen aus dem Text extrahiert werden.*
<ol>
    <details>
      <summary><b>ðŸŸ¡ Merkmalsextraktion (engl. feature extraction)</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Beginn der Merkmalsextraktion zum Zweck der Themenmodellierung</i>
      <summary>Themenmodellierung (engl. topic modeling)</summary>
      <i>Beginn der Themenmodellierung</i>
           NMF, LDA
    </details>
    <details>
      <summary><b>ðŸŸ¡ Merkmalsumwandlung (engl. feature transformation)</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Beginn der Merkmalsumwandlung in der Merkmale in eine geeignete Form gebracht werden.</i>
          .<br>
      <summary>Themenmodellierung (engl. topic modeling)</summary>
      <i>Beginn der Themenmodellierung</i>
           LSA
    </details>
    <details>
      <summary><b>ðŸŸ¡ Merkmalsauswahl (engl. feature selection)</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zum Ende werden die besten Merkmale ausgewÃ¤hlt.</i>
    </details>
</ol>    
<b>ðŸ”µ Merkmalslernen (engl. feature learning / representation learning)</b></br>
<i>Beginn der Modellbildung fÃ¼r Aufgabe<i>

### Pipeline Ausgabe (engl. Pipeline Output)
<b>ðŸŸ¢ Merkmalsanalyse (engl. feature-analysis)</b></br>
      <i>xxxxxxxxxxxx</i>
<ol>
    <details>
      <summary><b>ðŸŸ¢ Visualisierung</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;grafische Darstellung</i>
    </details>
    <details>
      <summary><b>ðŸŸ¢ Aggregation</b></summary>
      <i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numerische Darstellun</i>
    </details>
</ol>

### Post-Processing
*Beginn der Evaluation*
<ol>
  <details>
      <summary>ðŸŸ£ Evaluation</summary>
      <ol>
        <li> Aggregation</li>
        <i>blub blub, blub</i>
        <li> Visualisierung</li>
        <i>blub blub, blub</i>
      </ol>
  </details>
</ol>

### Referenzen
Detector
`KI-Detektor`

Bibliotheken
`Gensim`

<li>1</li>
````python
12535
````

<li>2</li>

### Codeblocks
````python
33333
````


### Installation

Prerequisites
Installation


### 
ðŸ“Š Ergebnisse
Themenverteilungen
Top-WÃ¶rter pro Thema
Modellvergleich